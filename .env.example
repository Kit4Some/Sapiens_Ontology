# Application Settings
APP_NAME=Ontology Reasoning System
APP_VERSION=0.1.0
ENVIRONMENT=development
LOG_LEVEL=INFO

# Neo4j Database
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password_here
NEO4J_DATABASE=neo4j
NEO4J_MAX_CONNECTION_POOL_SIZE=50

# LLM Settings
LLM_PROVIDER=openai
LLM_OPENAI_API_KEY=sk-your-openai-api-key
LLM_ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key
LLM_REASONING_MODEL=gpt-4-turbo-preview
LLM_CYPHER_MODEL=gpt-4-turbo-preview
LLM_EMBEDDING_MODEL=text-embedding-3-small
# Deterministic response settings
LLM_TEMPERATURE=0.0
LLM_SEED=42
LLM_TOP_P=1.0
LLM_MAX_TOKENS=4096

# ToG 3.0 MACER Settings
TOG_MAX_REASONING_DEPTH=5
TOG_EXPLORATION_WIDTH=10
TOG_CONFIDENCE_THRESHOLD=0.7
TOG_ENABLE_META_COGNITION=true

# QA Mode Settings (General Document QA Support)
# - benchmark: HotpotQA-style short answers (1-10 words)
# - general: Document QA with flexible answer lengths (up to 500 words)
# - auto: Detect based on question type (recommended)
TOG_QA_MODE=auto
TOG_DEFAULT_MAX_ANSWER_WORDS=100
TOG_ENABLE_EXTENDED_QUESTION_TYPES=true
TOG_ENABLE_NARRATIVE_ANSWERS=true

# Workflow Settings
WORKFLOW_MAX_ITERATIONS=10
WORKFLOW_TIMEOUT_SECONDS=120
WORKFLOW_ENABLE_CHECKPOINTING=true

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false
API_CORS_ORIGINS=["*"]

# =============================================================================
# LangGraph Checkpointing (PostgreSQL)
# =============================================================================
CHECKPOINT_BACKEND=memory
# Use "postgres" for production persistent checkpointing
# CHECKPOINT_BACKEND=postgres
CHECKPOINT_POSTGRES_URI=postgresql://ontology:ontology_pass@localhost:5432/ontology_checkpoints

# =============================================================================
# Telemetry (Opt-in Data Collection)
# =============================================================================
# Master switch - disabled by default for privacy
TELEMETRY_ENABLED=false

# What to collect (only applies if TELEMETRY_ENABLED=true)
TELEMETRY_COLLECT_PROMPTS=true
TELEMETRY_COLLECT_KG_DATA=true
TELEMETRY_COLLECT_METRICS=true

# Privacy settings
TELEMETRY_ANONYMIZE_DATA=true
TELEMETRY_SAMPLING_RATE=1.0

# Endpoint settings
TELEMETRY_ENDPOINT_URL=https://telemetry.sapiens.team/v1/collect
# TELEMETRY_API_KEY=your-api-key-here

# Batching settings
TELEMETRY_BATCH_SIZE=50
TELEMETRY_FLUSH_INTERVAL_SECONDS=300
